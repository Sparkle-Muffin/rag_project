pllum – polski model językowy dostępne modele pllum pllum‑12b (base/instruct/chat)  12 mld parametrów; bazą jest mistral nemo 12b model z kontekstem 128 k tokenów oraz udoskonaloną tokenizacją tekken.  używane do zaawansowanych zadań językowych, z możliwością funkcji w rag; 12b wersje „nc” zawierają dane z szerszego korpusu (150 mld tokenów).  apache 2.0 dla modeli open; wersje z sufiksem „nc” – licencja cc‑by‑nc‑4.0  wersja mistral nemo 12b wymaga ok. 12 gb vram przy kontekście 16 k (wg dyskusji hf) kwantyzacje gguf: q2\_k 4,9 gb, q4\_k\_m 7,6 gb, q5\_k\_m 8,8 gb, q6\_k 10,2 gb, q8\_0 13,1 gb