rodzina modeli llama – przegląd i wymagania sprzętowe (stan na sierpień 2025 r.) llama 4 (kwiecień 2025) architektura i kontekst – w modelach moe każdy token aktywuje jedynie 17 mld parametrów, mimo że całkowita liczba parametrów jest znacznie większa (scout ma 109 mld parametrów, 16 ekspertów; maverick – 400 mld parametrów, 128 ekspertów).  dzięki temu, przy tej samej liczbie aktywnych parametrów, llama 4 uzyskuje lepszą wydajność niż gęste modele.  okna kontekstowe są imponujące: 10 mln tokenów dla scouta i 1 mln tokenów dla mavericka