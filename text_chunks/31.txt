modele mistral – kompendium (stan na sierpień 2025) opisy poszczególnych modeli mistral nemo 12b model 12 mld parametrów wytrenowany we współpracy z nvidia. oferuje aż 128k kontekstu, jest wielojęzyczny i obsługuje wywoływanie funkcji. zastosowano nowy tokenizer tekken, który kompresuje kod źródłowy i wiele języków lepiej niż sentencepiece  wersja bf16 wymaga ok. 28 gb vram, natomiast dzięki uczeniu z kwantyzacją model można uruchamiać w fp8 na gpu z 16 gb vram nemo jest publikowany w licencji apache 2.0 i jest następcą mistral 7b.