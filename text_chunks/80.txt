modele gpt – szczegółowy przegląd dla rag (stan na sierpień 2025) 1. ewolucja serii gpt gpt‑3 (czerwiec 2020)  175 mld parametrów  standardowe okno kontekstowe ma 2 048 tokenów model potrafi wykonywać „few‑shot learning” i obsługiwać zadania bez fine‑tuningu.  składa się w 60 % z danych common crawl, 22 % z książek i treści licencjonowanych oraz 3 % z wikipedii  dla fp16/bfloat16 potrzeba ~350 gb pamięci gpu (2 bajty × 175 mld parametrów) w praktyce model jest dostępny tylko w chmurze.  model komercyjny – dostępny wyłącznie poprzez api openai/microsoft; prawa do wag posiada microsoft.  umożliwił generowanie esejów, kodu, dialogów i tłumaczeń; stał się podstawą wielu aplikacji oraz powstania chatgpt.