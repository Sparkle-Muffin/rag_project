rodzina modeli llama – przegląd i wymagania sprzętowe (stan na sierpień 2025 r.) llama 2 (lipiec 2023) wymagania sprzętowe – serwis hardware corner podaje, że 7‑miliardowy model w 4‑bitowej kwantyzacji (gptq) wymaga ok. 6 gb vram, a inference na cpu w formacie ggml/gguf potrzebuje 4 gb ram i 300 mb vram  wariant 13 b wymaga 10 gb vram lub 8 gb ram (ggml), natomiast model 70 b potrzebuje co najmniej 40 gb vram i 64 gb ram przy użyciu cpu