modele mistral – kompendium (stan na sierpień 2025) opisy poszczególnych modeli pixtral 12b i pixtral large pixtral 12b to pierwszy multimodalny model mistrala. składa się z 12 mld parametrów w dekoderze (na bazie mistral nemo) i 400 mln parametrów w enkoderze obrazu; model przyjmuje kilka obrazów oraz tekst, obsługuje zmienne rozmiary obrazów i ma 128k kontekstu jest dostępny w licencji apache 2.0; w precyzji bf16 wymaga 28 gb vram, w fp8 około 16 gb artykuł ori podaje, że do uruchomienia na vllm wystarczy 24 gb vram pixtral large (124 mld parametrów + 1 mld w enkoderze obrazu) ma kontekst 128k i przewyższa konkurencję na benchmarkach mathvista, docvqa i vqa v2 udostępniony jest w licencji badawczej; wymaga ok. 250 gb vram