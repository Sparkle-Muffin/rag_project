modele mistral – kompendium (stan na sierpień 2025) podsumowanie ekosystem mistral ai rozwija się bardzo dynamicznie: od kompaktowego mistral 7b, przez hybrydowe modele mixtral, wyspecjalizowane mathstral i codestral, po multimodalne pixtral i voxtral, modele reasoning (magistral), agentowe (devstral), embeddingowe oraz usługi ocr. wiele modeli jest open‑source (apache 2.0), co ułatwia ich wykorzystanie w projektach rag i lokalnych asystentach, a ich wymogi pamięci zaczynają się od 8 gb vram (voxtral mini, ministral 3b). modele premierowe (medium 3, magistral medium, devstral medium, mistral large, pixtral large) dostępne są poprzez api i adresują potrzeby korporacyjne związane z niską latencją, dużym kontekstem i wielomodalnością.  dzięki licencjom badawczym i komercyjnym mistral ai umożliwia zarówno eksperymentowanie, jak i produkcyjne zastosowania, oferując równocześnie narzędzia do własnego dostrajania (mistral‑inference, mistral‑finetune) oraz infrastruktury (mistral compute).