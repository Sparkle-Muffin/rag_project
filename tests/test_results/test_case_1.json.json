{
    "question": "Jakie modele LLaMa są dostępne?",
    "keywords": [
        "llama 1",
        "llama 2",
        "llama 3"
    ],
    "expected_answer": "Modele LLaMa 1, LLaMa 2 i LLaMa 3.",
    "model_answer": "Dostępne modele LLaMa obejmują różne generacje i warianty, które różnią się liczbą parametrów, obsługiwanym kontekstem oraz specjalizacją. Oto przegląd głównych modeli:\n\n### Generacje LLaMa:\n1. **LLaMA 1** (2023):\n   - Warianty: 7B, 13B, 65B parametrów.\n   - Obsługiwany kontekst: około 2K tokenów.\n   - Dostępność: Początkowo udostępnione na zasadach badawczych.\n\n2. **LLaMA 2** (lipiec 2023):\n   - Warianty: 7B, 13B, 70B parametrów.\n   - Ulepszenia: Wytrenowane na większym zbiorze danych (dużo większy niż LLaMA 1).\n   - Licencja: LLama Community License (pozwala na komercyjne wykorzystanie z pewnymi ograniczeniami dla dużych podmiotów).\n\n3. **LLaMA 3** (kwiecień 2024):\n   - Warianty: 8B, 70B parametrów.\n   - Ulepszenia: Zwiększone konteksty, wysoka dokładność, odświeżony tokenizer, zbiór danych 7B tokenów.\n\n4. **LLaMA 3.2** (wrzesień 2024):\n   - Warianty: 1B, 3B parametrów (przeznaczone dla urządzeń mobilnych i wbudowanych).\n   - Modele Vision: Obsługują tekst i obraz, rozpoznają diagramy, tabele, proste elementy wizualne.\n\n5. **LLaMA 4** (kwiecień 2025):\n   - Warianty: Scout, Maverick.\n   - Ulepszenia: Przewyższa Mistral 3.1 i Gemma 3 w zadaniach multimodalnych, dorównuje GPT-4 w benchmarkach reasoningowych.\n   - Zastosowania: Asystenci multimodalni (tekst + obraz), zaawansowane aplikacje RAG z dużym kontekstem.\n\n6. **CodeLLama** (sierpień 2023):\n   - Specjalizacja: Generacja kodu i obsługa zadań programistycznych.\n   - Warianty: 7B, 13B, 30B/33B/34B parametrów.\n   - Działanie: Z długim kontekstem (do 100K tokenów).\n\n### Modele Mistral:\n- **Modele otwarte** (dostępne na Hugging Face, licencja Apache 2.0):\n  - Mistral 7B, Mixtral 8×7B i 8×22B, CodeStral Mamba, MathStral, Mistral Nemo, Pixtral 12B, serie Mistral Small/DevStral Small/Magistral Small, Voxtral Small/Mini itd.\n  - Wymagania sprzętowe: Znaczna pamięć VRAM podczas inferencji (minimalne wartości podane w tabeli).\n\n### Podsumowanie:\nDostępne modele LLaMa obejmują różne generacje i specjalizacje, od małych modeli mobilnych po duże modele multimodalne. Wybór konkretnego modelu zależy od wymagań dotyczących zasobów sprzętowych, zastosowań (np. generacja tekstu, kodu, obsługa obrazów) oraz ograniczeń licencyjnych.",
    "ok": true
}