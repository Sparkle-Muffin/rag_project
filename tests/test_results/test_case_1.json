{
    "question": "Jakie modele LLaMa są dostępne?",
    "required_keywords": [
        "llama 1",
        "llama 2",
        "llama 3",
        "llama 4"
    ],
    "optional_keywords": [
        "llama 3.1",
        "llama 3.2",
        "llama 4 scout",
        "llama 4 maverick",
        "llama 4 behemoth",
        "code llama",
        "llama 3.1 8b",
        "llama 3.1 70b",
        "llama 3.1 405b",
        "llama 3.2 1b",
        "llama 3.2 3b",
        "llama 3.2 vision 11b",
        "llama 3.2 vision 90b",
        "llama 3 8b",
        "llama 3 70b",
        "llama 2 7b",
        "llama 2 13b",
        "llama 2 70b",
        "llama 1 7b",
        "llama 1 13b",
        "llama 1 65b"
    ],
    "expected_answer": "Dostępne są modele LLaMa 1, LLaMa 2, LLaMa 3 i LLaMa 4.",
    "model_answer": "Na podstawie dostarczonego kontekstu, rodzina modeli LLaMA obejmuje kilka generacji i wariantów. Oto przegląd dostępnych modeli (stan na sierpień 2025 r.):\n\n### Generacje LLaMA:\n1. **LLaMA 1** (2023):\n   - Warianty: 7B, 13B, 65B parametrów.\n   - Obsługują kontekst około 2K tokenów.\n   - Dostępne wyłącznie na zasadach badawczych.\n\n2. **LLaMA 2** (lipiec 2023):\n   - Warianty: 7B, 13B, 70B.\n   - Modele wytrenowane na większym zbiorze danych.\n   - Licencjonowane na zasadach LLaMA Community License.\n\n3. **LLaMA 3** (kwiecień 2024):\n   - Warianty: 8B, 70B.\n   - Znaczące ulepszenia: większe konteksty, lepsza dokładność, odświeżony tokenizer, zbiór danych 7B tokenów.\n\n4. **LLaMA 3.2** (wrzesień 2024):\n   - Warianty: 1B, 3B (przeznaczone do urządzeń mobilnych i wbudowanych).\n   - Modele Vision obsługują tekst i obraz, rozpoznają diagramy, tabele itp.\n\n5. **LLaMA 4** (kwiecień 2025):\n   - Warianty: Scout, Maverick.\n   - LLaMA 4 Scout przewyższa Mistral 3.1 i Gemma 3 w zadaniach multimodalnych.\n   - LLaMA 4 Maverick dorównuje GPT-4 w benchmarkach rozumowania.\n\n### Specjalistyczne warianty:\n- **CodeLLama** (sierpień 2023):\n  - Warianty: 7B, 13B, 30B/33B/34B.\n  - Specjalizują się w generacji kodu i obsłudze zadań programistycznych.\n  - Działają z długim kontekstem (do 100K tokenów).\n\n### Modele Mistral:\n- Obejmują różne warianty, takie jak Mistral 7B, Mixtral, Codestral Mamba, Mathstral, itp.\n- Dostępne na Hugging Face i licencjonowane na Apache 2.0.\n- Wymagają znacznej pamięci VRAM podczas inferencji.\n\n### Podsumowanie:\nDostępne modele LLaMA obejmują różne generacje (1–4) oraz specjalistyczne warianty (np. CodeLLama). Wybór modelu zależy od wymagań dotyczących zasobów sprzętowych, zastosowań (np. multimodalne, generacja kodu) i ograniczeń licencyjnych.",
    "required_keywords_score": 100.0,
    "optional_keywords_score": 14.285714285714285,
    "total_keywords_score": 28.000000000000004,
    "evaluation_score": 9,
    "descriptive_evaluation": "Odpowiedź modelu jest bardzo szczegółowa i zawiera więcej informacji niż odpowiedź wzorcowa. Obejmuje ona nie tylko listę generacji LLaMA, ale także warianty parametrów, daty wydania, specjalistyczne modele (np. CodeLLama) oraz dodatkowe informacje o zastosowaniach i licencjach. Jest to odpowiedź wyczerpująca, choć nieco bardziej rozbudowana niż wymagane.",
    "answer_generation_time_s": 137
}