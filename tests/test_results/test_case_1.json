{
    "question": "Jakie modele LLaMa są dostępne?",
    "required_keywords": [
        "llama 1",
        "llama 2",
        "llama 3",
        "llama 4"
    ],
    "optional_keywords": [
        "llama 3.1",
        "llama 3.2",
        "llama 4 scout",
        "llama 4 maverick"
    ],
    "expected_answer": "Modele LLaMa 1, LLaMa 2 i LLaMa 3.",
    "model_answer": "Na podstawie dostarczonego kontekstu, rodzina modeli LLaMA obejmuje kilka generacji i wariantów. Oto przegląd dostępnych modeli (stan na sierpień 2025 r.):\n\n### Generacje i Warianty:\n1. **LLaMA 1** (2023):\n   - Modele: `7B`, `13B`, `65B` parametrów.\n   - Obsługują kontekst około 2k tokenów.\n   - Dostępne wyłącznie na zasadach badawczych.\n\n2. **LLaMA 2** (lipiec 2023):\n   - Modele: `7B`, `13B`, `70B`.\n   - Wytrenowane na większym zbiorze danych (~7 bln tokenów).\n   - Licencjonowane na zasadach LLaMA Community License.\n\n3. **LLaMA 3** (kwiecień 2024):\n   - Modele: `8B`, `70B`.\n   - Znaczące ulepszenia: większe konteksty, lepsza dokładność, odświeżony tokenizer.\n\n4. **LLaMA 3.2** (wrzesień 2024):\n   - Modele `1B` i `3B` przeznaczone do urządzeń mobilnych i wbudowanych.\n   - Modele Vision obsługują tekst i obraz, rozpoznając diagramy, tabele itp.\n\n5. **LLaMA 4** (kwiecień 2025):\n   - Modele: `Scout` i `Maverick`.\n   - `Scout` przewyższa Mistral 3.1 i Gemma 3 w zadaniach multimodalnych.\n   - `Maverick` dorównuje GPT-4 w benchmarkach rozumowania, ale wymaga dużej infrastruktury.\n\n6. **CodeLLama** (sierpień 2023):\n   - Specjalizacja w generacji kodu i obsłudze zadań programistycznych.\n   - Modele: `7B`, `13B`, `30B/33B/34B`.\n   - Obsługują długi kontekst (do 100k tokenów).\n\n### Dodatkowe Informacje:\n- **Licencja**: Większość modeli LLaMA jest objęta LLaMA Community License, która umożliwia komercyjne wykorzystanie (z wyjątkami dla podmiotów z ponad 700 mln aktywnych użytkowników miesięcznie).\n- **Wymagania Sprzętowe**: Mniejsze modele (1B–8B) mogą działać na pojedynczej karcie GPU z 16 GB VRAM lub nawet na CPU. Większe modele (70B i więcej) wymagają środowisk z wieloma GPU i setkami GB pamięci.\n\nTe modele są przeznaczone do różnych zastosowań, od urządzeń mobilnych po zaawansowane systemy RAG (Retrieval-Augmented Generation) i asystentów multimodalnych.",
    "required_keywords_score": 100.0,
    "optional_keywords_score": 25.0,
    "total_keywords_score": 62.5,
    "descriptive_evaluation": "Odpowiedź modelu jest bardzo szczegółowa i zawiera więcej informacji niż odpowiedź wzorcowa. Oprócz podstawowych generacji (LLaMA 1, 2, 3), model opisuje również dodatkowe warianty (np. LLaMA 3.2, LLaMA 4, CodeLLama) oraz szczegóły dotyczące licencji i wymagań sprzętowych. Chociaż odpowiedź wykracza poza zakres pytania, jest to bardzo przydatne rozszerzenie kontekstu.",
    "evaluation_score": 9,
    "answer_generation_time_s": 132
}